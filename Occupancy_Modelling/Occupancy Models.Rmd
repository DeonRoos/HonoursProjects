---
title: "Occupancy models"
author: "Deon Roos"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: flatly
    highlight: monochrome
    code_folding: hide
    toc: true
    toc_depth: 2
    toc_float: true
    collapsed: false
    smooth_scroll: false
    df_round1_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE)
```

# Where are species present and why are they present?

A fundamental question in ecology is: where are species present, and why? For example, why are elephants present in the north of Etosha nature reserve in Namibia, but not in the south of the reserve? Is it due to water availability? Food? Could predators play a role?

The best tool available for answering these types of questions is occupancy modeling, originally developed by Daryl MacKenzie et al in [2002](https://doi.org/10.1890/0012-9658(2002)083[2248:ESORWD]2.0.CO;2). This modelling framework built on concepts already developed for estimating survival of *individual* animals, called the Cormack-Jolly-Seber model (note that Cormack and Jolly independently developed this model *while they worked in Aberdeen University* - a vital and internationally renowned model was developed right here in bloody Aberdeen!)

The problem that occupancy models solve is subtle but insanely crucial.

Assume I want to determine where elephants are present in Etosha nature reserve in Namibia. I do a bunch of surveys where I go to various sites throughout the park. Whenever I spot an elephant I note down that elephants are present at that location. When I don't see any elephants I also record that. My dataset might look something like:

```{r}
set.seed(1988)
etosha <- data.frame(
  site = 1:10,
  elephants = rbinom(n = 10, size = 1, prob = 0.4)
)
etosha
```

When `elephants` is `1`, then I saw them at that site, and when `elephants` is `0`, then I didn't see them.

To figure out the probability that a site is occupied, I can run a Bernoulli Generalised Linear Model. The Bernoulli distribution (named after [Jacob Bernoulli](https://en.wikipedia.org/wiki/Jacob_Bernoulli)) is a type of distribution that will generate (or expect) values of `1` or `0`; perfect here because our data can only be `1` or `0`.

The model would be:

$$
y_i \sim Bernoulli(p_i) \\
logit(p_i) = \beta_0
$$

where:

* $y$ is our observation (`elephants` in the `etosha` dataset)

* $i$ is the index, here being which `site` the data was collected from

* $\sim$ means "generated according to" (or "our data is the same as would be generated by the following distribution")

* $Bernoulli$ is a type of distribution that will generate either 0 or 1

* $p$ is the probability of success (i.e. there is $p$ probability that we see an elephant). We can't possibly know what $p$ is when we collect the data, so we need to figure it out with statistics. (The $i$ means each site *could* have a different probability - but we're not doing that yet)

* $logit$ is the link function to ensure that $p$ remains between 0% and 100%. Specifically, it's a little bit of maths: $log(\frac{p}{1-p})$, which is the natural log of the probability to succeed ($p$) divided by the probability to fail ($1-p$).

* $\beta_0$ is the intercept which here, given we have nothing else in this part of the model, means the average probability to see an elephant.

Here's how we'd run that model in `R` (click the `Show` button to see the code):

```{r}
mod <- glm(elephants ~ 1,
           data = etosha,
           family = binomial)
```

Which returns the estimate of $\beta_0$ (or average probability to detect elephants *on the link function scale*, i.e. it's a logit value):

```{r}
summary(mod)
```

The estimate for `(Intercept)` (or $\beta_0$) is `-1.3863`, which we can convert into a probability by doing the inverse logit (`R` has a nice way to do this using the function `plogis()`):

```{r}
plogis(-1.3863)
```

We now have our estimate as a proportion (which we can multiply by 100 to get to percentage), so we can say there's a roughly 20% chance that an elephant occupies a site in Etosha.

Or can we?

# Imperfect detection

This 20% estimate is actually the product of two probabilities. For us to detect an elephant two things need to happen. 

1. The elephant must obviously be there, with some probability. We can call this probability $\psi$ (called "psi", pronounced like "sigh").

2. I have to *see* the elephant. This will never have a 100% chance no matter how good I am at spotting elephants. We can call this probability $p$.

So all of the `1`'s in our `etosha` dataset are the result of both of these probabilities, or $\psi \times p$, and not just $\psi$ like we want.

There's no shortage of reasons why you might not see an elephant despite it being there. It can be as simple and dumb as the elephant was behind a bush when I checked that site. This reflects something called "imperfect detection", i.e. just cause it's there doesn't mean we're going to see it.

Imperfect detection is not an issue for the `1`'s in our data - when we see an elephant. If you see an elephant, you know it's there. That's easy and obvious. The complication created by imperfect detections happens when we __*don't*__ detect an elephant; when `elephants` is `0`. What does that mean? Are elephants actually absent from that site or are they present but I didn't see them?

That's the problem! The `0`'s have multiple meanings. It's not as simple as "if I don't see an elephant, there are not elephants there".

> [Bit of a rant here] This is a massive problem in a particular subset of biology where people use "Species Distribution Models" (or SDMs) to understand where species are (i.e. their ranges) and why they are there. To avoid confusion, the term SDM means basically nothing statistically as there is no such thing as a "Species Distribution Model" (i.e. it's not like GLM that means something very specific). SDMs really describe an output, and not a statistical model. In fact, some SDMs are simply GLMs, like the one above, which ignores imperfect detection. If someone tells me they fit SDMs, I generally treat it as a red flag; there's a good chance they don't understand stats well enough to do the research they want to responsibly.

Generally, when people say they ran an SDM, what they *mean* is, they ran something akin to the GLM above. Specifically, they would treat the `elephants` column in our `etosha` dataset as being a faithful measure of elephants being either present or absent, and not elephants are present __*and detected*__ or just absent.

They ignore imperfect detection; they ignore the fact that `0`'s have multiple meanings.

Occupancy models do not ignore this, and that's why they're such a powerful tool. Here's how they do it.

# Occupancy models

The first part of the occupancy model (which I'll call the "state model" because it's trying to determine the "state" of a site - either occupied or not) looks remarkably similar to the GLM above:

$$
z_i \sim Bernoulli(\psi_i)\\
logit(\psi_i) = \beta_0
$$

They look similar, because they're both $Bernoulli$ GLMs! But they differ in two important ways,

* $z$ is the **true** presence or absence of elephants in site $i$

* $\psi$ is the probability to be present

Ok, so the labels have changed, but how does that magically solve the problem of imperfect detection? Well, if we left it there it wouldn't be solved. We need something that will deal with impefect detection; a second GLM.

The second GLM (which I'll call the "observation model") also looks remarkably similar:

$$
y_{i,j} \sim Bernoulli(p_{i,j} \times z_i)\\
logit(p_{i,j}) = \alpha_0
$$

It's yet another $Bernoulli$ GLM but with some really important changes.

* $y$ is now the **detection** or not of an elephant

* $j$ is *survey*, which means we have *multiple surveys*, not just one like in our first GLM example above

* $p$ is the probability to detect an elephant at site $i$ in survey $j$ (e.g. what is the probability to detect an elephant in site 1 in the third survey?)

Importantly, the probability to detect elephants ($p$) is *multiplied* by $z$. What's $z$? Well that's the true occupancy state of that site from the first GLM. It's this multiplication that allows the two models to "speak" to each other.

If there are elephants in a site ($z = 1$), then $p \times 1 = p$. If elephants are absent from a site ($z = 0$), then $p \times 0 = 0$. This means you cannot detect elephants if they aren't there. That's blindingly obvious... But this stupidly simple logic is missing from our starting GLM!

Keep in mind that we don't know $z$ - that's the "true" occupancy state of a site. It's something called a "latent variable", meaning we never actually measure or record this in the field. Instead, much like with parameters, we use the data we have collected to estimate this variable for each site that we have data from.

That's how occupancy model knows that you can only detect elephants if they're present, and if they aren't present then you can't see them! That's the beauty of occupancy models and why they are far, far superior to traditional SDMs!

# The robust design and closure

Ok, great, we've got a clever modelling framework but how does the above help us resolve if we go to a site and don't see an elephant? How do we distinguish between a "true negative" (i.e. we don't see elephants because there aren't any elephants) versus a "false negative" (i.e. we don't see elephants but they were there)?

This is where the subscript $j$ in the observation model becomes important. Imagine we visit a site once and we see no elephants. With no additional information you have absolutely no way to determine if it was occupied or not. You just know you didn't see any elephants.

But imagine I went back to that same site the next day. This time I do see elephants. We learn a few things from this. First, we know elephants are present at the site. Secondly, we learn that the first survey must have been a false negative - we just didn't see elephants despite them being there.

This introduces a key assumption in occupancy models. For my above statement to be "true" and make sense, then I have to assume elephants were *always* present, and they didn't just happen to move into the site on the second day.

This assumption is called the "assumption of closure". This is often poorly understood, where people interpret it as meaning the site is physically "closed" - as in there is some kind of "fence" that prevents animals from moving. This is not correct. "Closure" here, means "demographically closed", i.e. if the species was present in survey one, then it is present in survey two and survey three, survey four, and so on, until you stop surveying.

> This imposes two important considerations for field work. We need to survey sites on multiple occasions. Meaning, we can't have a "one-and-done" approach to surveying; we need to leave cameras in situ for more than one sampling period (though it's for us to define what our sampling period is - it could be an hour, a day, a week - so long as we can assume that if the species is present at the first survey, then it will be present at the last survey). Secondly, these sampling occasions cannot extend over such a long period of time that it becomes increasingly hard, or unreasonable, to assume the species could not have gone locally extinct or (re)colonised the area. 

In practice, a minimum of three survey occasions is required (e.g., three days, three hours, or three defined sampling periods). But additionally, you don't want to monitor the same site for so long the species could go locally extinct (obviously dependent on the species you're working with). If such local extinctions and recolonisations are likely at a site, then you can extend from the single season occupancy models (the type of occupancy model that we're talking about here) into multi-season occupancy models.

This form of sampling (repeatedly sampling the same site a minimum of three times) is called "the robust design" and is very often used in more "robust" (i.e. responsible or trustworthy) research.

# The data

I'm going to simulate data for an occupancy model to give you an idea of how you data should be organised. To do so, I'll use the `R` package that you'll eventually use in your own analysis, `spOccupancy` (short for spatial occupancy - we'll get to the spatial part later).

```{r}
library(spOccupancy)
set.seed(1988)
dat <- simOcc(J.x = 5, J.y = 2, n.rep = rep(3, times = 10), beta = c(4), alpha = c(0))
obs <- dat$y
```

Our dataset is going to look a little different. Keep in mind that with the robust design, we need to monitor each site multiple times, often three or more. That means we can't just have a single column for detections like we did in the `etosha` example above. Instead, here would data will look like:

```{r}
obs
```

Each row is one of our ten sites, and each column is one of our three sampling periods. Notice anything? In site 1, or `[1,]`, we never see elephants. But this could be because we didn't see them rather than them not being there. Same problem as before.

However, this time in site 2, or `[2,]`, we see elephants on day 1, we don't see them on day 2, then we see them again on day 3. Are elephants present at this site? Yes, clearly. We see them on 2 out of 3 surveys, so they're there.

This is where we start getting information that helps us understand what our detection probability is. Ignore occupancy models for a moment. If we focus on site 2, we might guess that our detection probability is maybe about 66% (2 out of 3). If so, then we'd think we have a 66% chance of detecting elephants on any survey if they're present. That guess helps us figure out how likely it is that elephants were actually absent